{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114709e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"dominguesm/alpaca-data-pt-br\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88948894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Example usage of the GPT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pierreguillou/gpt2-small-portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47093c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f0e2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"concat\"] = (\n",
    "    df[\"instruction\"] + \"\\n\\n\" + df[\"input\"].fillna(\"\") + \"\\n\\n\" + df[\"output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3deb0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column with count of tokens for each row\n",
    "df[\"tokens\"] = df[\"concat\"].apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b62a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    51759.000000\n",
       "mean        74.283371\n",
       "std         40.517703\n",
       "min         10.000000\n",
       "25%         38.000000\n",
       "50%         67.000000\n",
       "75%        110.000000\n",
       "90%        127.000000\n",
       "95%        136.000000\n",
       "99%        159.000000\n",
       "max        838.000000\n",
       "Name: tokens, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tokens\"].describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb2140",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e05368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.92M\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from model import GPT, GPTConfig\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "config = GPTConfig(\n",
    "    block_size=128,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    n_embd=128,\n",
    "    n_experts=8,\n",
    "    capacity_factor=1.25,\n",
    "    k=2,\n",
    "    experts_weight=0.01,\n",
    "    router_weight=0.001,\n",
    "    dropout=0.2,\n",
    "    bias=True,\n",
    ")\n",
    "\n",
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63bff4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    df[\"concat\"].tolist(),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    ")\n",
    "\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "targets = input_ids.clone()\n",
    "\n",
    "targets[:, :-1] = input_ids[:, 1:]\n",
    "targets[:, -1] = -1\n",
    "\n",
    "# convert targets 0 to -1\n",
    "targets[targets == 0] = -1\n",
    "\n",
    "# print(\"input ids:\", inputs[\"input_ids\"], \"shape:\", inputs[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d8cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert 0 -> 1 and 1 -> 0 in attention mask\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "# create a new upper triangular mask\n",
    "upper_mask = torch.triu(torch.ones(input_ids.shape[1], input_ids.shape[1]), diagonal=1)\n",
    "\n",
    "# apply the mask to the attention mask\n",
    "attention_mask = attention_mask.unsqueeze(1) * upper_mask.unsqueeze(0)\n",
    "\n",
    "# conver to bool\n",
    "attention_mask = attention_mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78450a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 50257])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids[:5, :], attention_mask=attention_mask[:5, :, :])[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2584e90",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1995665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to device\n",
    "model = model.to(device)\n",
    "input_ids = input_ids[:32, :].to(device)  # limit to 16 for testing\n",
    "attention_mask = attention_mask[:32, :, :].to(device)\n",
    "targets = targets[:32, :].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f61c1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 10.92919921875\n",
      "perplexity: 55781.59375\n",
      "using fused AdamW: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a40dd6296d40c0bc2abc7047e22ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m model.eval()\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     logits, loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m perplexity = torch.exp(loss)\n\u001b[32m     36\u001b[39m pbar.set_postfix(loss=loss.item(), perplexity=perplexity.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repos\\nanoGPT-moe\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repos\\nanoGPT-moe\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repos\\nanoGPT-moe\\model.py:244\u001b[39m, in \u001b[36mGPT.forward\u001b[39m\u001b[34m(self, idx, attention_mask, targets)\u001b[39m\n\u001b[32m    242\u001b[39m loss = \u001b[32m0\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transformer.h:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     x, block_loss = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     loss = loss + block_loss\n\u001b[32m    246\u001b[39m x = \u001b[38;5;28mself\u001b[39m.transformer.ln_f(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repos\\nanoGPT-moe\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repos\\nanoGPT-moe\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repos\\nanoGPT-moe\\model.py:140\u001b[39m, in \u001b[36mBlock.forward\u001b[39m\u001b[34m(self, x, attention_mask)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, attention_mask=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    139\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.attn(\u001b[38;5;28mself\u001b[39m.ln_1(x), attention_mask=attention_mask)\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     o, loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     x = x + o\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x, loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repos\\nanoGPT-moe\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repos\\nanoGPT-moe\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repos\\nanoGPT-moe\\moe_layer.py:110\u001b[39m, in \u001b[36mMoELayer.forward\u001b[39m\u001b[34m(self, H)\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# (<=capacity, d)\u001b[39;00m\n\u001b[32m    109\u001b[39m     tokens_e = H_flat[mask_e]\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     expert_inputs.append(tokens_e)\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# 7. Forward each expert\u001b[39;00m\n\u001b[32m    113\u001b[39m expert_outputs = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits, loss = model(input_ids, attention_mask, targets)\n",
    "    # print(\"logits:\", logits, \"shape:\", logits.shape)\n",
    "print(\"loss:\", loss.item() if loss is not None else \"N/A\")\n",
    "if loss is not None:\n",
    "    perplexity = torch.exp(loss)\n",
    "    print(\"perplexity:\", perplexity.item())\n",
    "\n",
    "# pred_tokens = logits.argmax(dim=-1)\n",
    "# tokens = pred_tokens[0].tolist()\n",
    "# print(\"predicted tokens:\", tokens)\n",
    "# print(\"predicted text:\", tokenizer.decode(tokens))\n",
    "\n",
    "optimizer = model.configure_optimizers(\n",
    "    weight_decay=0.0,\n",
    "    learning_rate=3e-3,\n",
    "    betas=(0.9, 0.95),\n",
    "    device_type=\"cuda\",\n",
    ")\n",
    "\n",
    "pbar = tqdm(range(1000), desc=\"Training Epochs\")\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = model(input_ids, attention_mask, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits, loss = model(input_ids, attention_mask, targets)\n",
    "\n",
    "    perplexity = torch.exp(loss)\n",
    "    pbar.set_postfix(loss=loss.item(), perplexity=perplexity.item())\n",
    "\n",
    "    pred_tokens = logits.argmax(dim=-1)\n",
    "    tokens = pred_tokens[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83d7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text after epoch 358: Dplplplplplplplplplpl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_4208\\653658135.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['generated_text'] = [tokenizer.decode(generated_ids[i].tolist()) for i in range(len(generated_ids))]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(\n",
    "        input_ids[:, :1].clone(),\n",
    "        max_new_tokens=10,\n",
    "        temperature=0.1,\n",
    "        top_k=1,\n",
    "        greedy=False,\n",
    "    )\n",
    "generated_text = tokenizer.decode(generated_ids[0].tolist())\n",
    "_df = df.head(32)\n",
    "_df[\"generated_text\"] = [\n",
    "    tokenizer.decode(generated_ids[i].tolist()) for i in range(len(generated_ids))\n",
    "]\n",
    "print(f\"Generated text after epoch {epoch + 1}: {generated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0baa228f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>concat</th>\n",
       "      <th>tokens</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dê três dicas para se manter saudável.</td>\n",
       "      <td></td>\n",
       "      <td>1. Coma uma dieta equilibrada e certifique-se ...</td>\n",
       "      <td>Dê três dicas para se manter saudável.\\n\\n\\n\\n...</td>\n",
       "      <td>62</td>\n",
       "      <td>Dplplplplplplplplplpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quais são as três cores primárias?</td>\n",
       "      <td></td>\n",
       "      <td>As três cores primárias são vermelho, azul e a...</td>\n",
       "      <td>Quais são as três cores primárias?\\n\\n\\n\\nAs t...</td>\n",
       "      <td>23</td>\n",
       "      <td>Qu slo slo slo slo slo slo slo slo slo slo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Descreva a estrutura de um átomo.</td>\n",
       "      <td></td>\n",
       "      <td>Um átomo é composto de um núcleo, que contém p...</td>\n",
       "      <td>Descreva a estrutura de um átomo.\\n\\n\\n\\nUm át...</td>\n",
       "      <td>78</td>\n",
       "      <td>Descrecrecrecrecrecrecrecrecre esta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Como podemos reduzir a poluição do ar?</td>\n",
       "      <td></td>\n",
       "      <td>Há várias maneiras de reduzir a poluição do ar...</td>\n",
       "      <td>Como podemos reduzir a poluição do ar?\\n\\n\\n\\n...</td>\n",
       "      <td>101</td>\n",
       "      <td>Comolhelhelhelhelhelhelhelhelhelhe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finja que você é um gerente de projeto de uma ...</td>\n",
       "      <td></td>\n",
       "      <td>Eu tive que tomar uma decisão difícil quando e...</td>\n",
       "      <td>Finja que você é um gerente de projeto de uma ...</td>\n",
       "      <td>135</td>\n",
       "      <td>Fin for for for for for for for for for for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Identifique o estranho.</td>\n",
       "      <td>Twitter, Instagram, Telegrama</td>\n",
       "      <td>Telegrama</td>\n",
       "      <td>Identifique o estranho.\\n\\nTwitter, Instagram,...</td>\n",
       "      <td>19</td>\n",
       "      <td>Identdentdentdentdentdentdentdentdentdent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explicar por que a seguinte fração é equivalen...</td>\n",
       "      <td>4/16</td>\n",
       "      <td>A fração 4/16 é equivalente a 1/4 porque ambos...</td>\n",
       "      <td>Explicar por que a seguinte fração é equivalen...</td>\n",
       "      <td>62</td>\n",
       "      <td>Explicplicplicplicplicplicplicplicplicplic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Escreva uma história curta na narração em terc...</td>\n",
       "      <td></td>\n",
       "      <td>John estava em uma encruzilhada em sua vida. E...</td>\n",
       "      <td>Escreva uma história curta na narração em terc...</td>\n",
       "      <td>133</td>\n",
       "      <td>Es 37 37 37 37 37 37 37 37 37 37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Avalie esta frase para erros ortográficos e gr...</td>\n",
       "      <td>Ele finished sua refeição e deixou o restourant</td>\n",
       "      <td>Ele terminou a refeição e saiu do restaurante.</td>\n",
       "      <td>Avalie esta frase para erros ortográficos e gr...</td>\n",
       "      <td>36</td>\n",
       "      <td>AAAAAAAAAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Como Júlio César morreu?</td>\n",
       "      <td></td>\n",
       "      <td>Júlio César foi assassinado por um grupo de at...</td>\n",
       "      <td>Como Júlio César morreu?\\n\\n\\n\\nJúlio César fo...</td>\n",
       "      <td>50</td>\n",
       "      <td>Comolhelhelhelhelhelhelhelhelhelhe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qual é a capital da França?</td>\n",
       "      <td></td>\n",
       "      <td>A capital da França é Paris.</td>\n",
       "      <td>Qual é a capital da França?\\n\\n\\n\\nA capital d...</td>\n",
       "      <td>18</td>\n",
       "      <td>Qualirroirroirro 7 7 7 7 7 7 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gerar uma lista de dez itens que uma pessoa po...</td>\n",
       "      <td></td>\n",
       "      <td>1. Tenda 2. Sacos de dormir 3. lanterna 4. fós...</td>\n",
       "      <td>Gerar uma lista de dez itens que uma pessoa po...</td>\n",
       "      <td>83</td>\n",
       "      <td>G Soviética Soviética Soviética Soviética Sovi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Discutir as causas da Grande Depressão</td>\n",
       "      <td></td>\n",
       "      <td>A Grande Depressão foi uma grave crise econômi...</td>\n",
       "      <td>Discutir as causas da Grande Depressão\\n\\n\\n\\n...</td>\n",
       "      <td>94</td>\n",
       "      <td>Diserarerarerarerarerarerarerarerarerarerar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Classifique o seguinte em animais, plantas e m...</td>\n",
       "      <td>Árvore de carvalho, minério de cobre, elefante</td>\n",
       "      <td>Carvalho: Planta de minério de cobre: Elefante...</td>\n",
       "      <td>Classifique o seguinte em animais, plantas e m...</td>\n",
       "      <td>39</td>\n",
       "      <td>Classdentdentdentdentdentdentdentdentdentdent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explicar o uso de incorporações de palavras no...</td>\n",
       "      <td></td>\n",
       "      <td>As incorporações de palavras são uma das ferra...</td>\n",
       "      <td>Explicar o uso de incorporações de palavras no...</td>\n",
       "      <td>128</td>\n",
       "      <td>Ex alimentar alimentar alimentar alimentar ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Descreva a função de uma placa-mãe de computador</td>\n",
       "      <td></td>\n",
       "      <td>Uma placa-mãe de computador é a placa de circu...</td>\n",
       "      <td>Descreva a função de uma placa-mãe de computad...</td>\n",
       "      <td>115</td>\n",
       "      <td>Deslhelhelhelhelhelhelhelhelhelhe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          instruction  \\\n",
       "0              Dê três dicas para se manter saudável.   \n",
       "1                  Quais são as três cores primárias?   \n",
       "2                   Descreva a estrutura de um átomo.   \n",
       "3              Como podemos reduzir a poluição do ar?   \n",
       "4   Finja que você é um gerente de projeto de uma ...   \n",
       "5                             Identifique o estranho.   \n",
       "6   Explicar por que a seguinte fração é equivalen...   \n",
       "7   Escreva uma história curta na narração em terc...   \n",
       "8   Avalie esta frase para erros ortográficos e gr...   \n",
       "9                            Como Júlio César morreu?   \n",
       "10                        Qual é a capital da França?   \n",
       "11  Gerar uma lista de dez itens que uma pessoa po...   \n",
       "12             Discutir as causas da Grande Depressão   \n",
       "13  Classifique o seguinte em animais, plantas e m...   \n",
       "14  Explicar o uso de incorporações de palavras no...   \n",
       "15   Descreva a função de uma placa-mãe de computador   \n",
       "\n",
       "                                              input  \\\n",
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     \n",
       "5                     Twitter, Instagram, Telegrama   \n",
       "6                                              4/16   \n",
       "7                                                     \n",
       "8   Ele finished sua refeição e deixou o restourant   \n",
       "9                                                     \n",
       "10                                                    \n",
       "11                                                    \n",
       "12                                                    \n",
       "13   Árvore de carvalho, minério de cobre, elefante   \n",
       "14                                                    \n",
       "15                                                    \n",
       "\n",
       "                                               output  \\\n",
       "0   1. Coma uma dieta equilibrada e certifique-se ...   \n",
       "1   As três cores primárias são vermelho, azul e a...   \n",
       "2   Um átomo é composto de um núcleo, que contém p...   \n",
       "3   Há várias maneiras de reduzir a poluição do ar...   \n",
       "4   Eu tive que tomar uma decisão difícil quando e...   \n",
       "5                                           Telegrama   \n",
       "6   A fração 4/16 é equivalente a 1/4 porque ambos...   \n",
       "7   John estava em uma encruzilhada em sua vida. E...   \n",
       "8      Ele terminou a refeição e saiu do restaurante.   \n",
       "9   Júlio César foi assassinado por um grupo de at...   \n",
       "10                       A capital da França é Paris.   \n",
       "11  1. Tenda 2. Sacos de dormir 3. lanterna 4. fós...   \n",
       "12  A Grande Depressão foi uma grave crise econômi...   \n",
       "13  Carvalho: Planta de minério de cobre: Elefante...   \n",
       "14  As incorporações de palavras são uma das ferra...   \n",
       "15  Uma placa-mãe de computador é a placa de circu...   \n",
       "\n",
       "                                               concat  tokens  \\\n",
       "0   Dê três dicas para se manter saudável.\\n\\n\\n\\n...      62   \n",
       "1   Quais são as três cores primárias?\\n\\n\\n\\nAs t...      23   \n",
       "2   Descreva a estrutura de um átomo.\\n\\n\\n\\nUm át...      78   \n",
       "3   Como podemos reduzir a poluição do ar?\\n\\n\\n\\n...     101   \n",
       "4   Finja que você é um gerente de projeto de uma ...     135   \n",
       "5   Identifique o estranho.\\n\\nTwitter, Instagram,...      19   \n",
       "6   Explicar por que a seguinte fração é equivalen...      62   \n",
       "7   Escreva uma história curta na narração em terc...     133   \n",
       "8   Avalie esta frase para erros ortográficos e gr...      36   \n",
       "9   Como Júlio César morreu?\\n\\n\\n\\nJúlio César fo...      50   \n",
       "10  Qual é a capital da França?\\n\\n\\n\\nA capital d...      18   \n",
       "11  Gerar uma lista de dez itens que uma pessoa po...      83   \n",
       "12  Discutir as causas da Grande Depressão\\n\\n\\n\\n...      94   \n",
       "13  Classifique o seguinte em animais, plantas e m...      39   \n",
       "14  Explicar o uso de incorporações de palavras no...     128   \n",
       "15  Descreva a função de uma placa-mãe de computad...     115   \n",
       "\n",
       "                                       generated_text  \n",
       "0                               Dplplplplplplplplplpl  \n",
       "1          Qu slo slo slo slo slo slo slo slo slo slo  \n",
       "2                 Descrecrecrecrecrecrecrecrecre esta  \n",
       "3                  Comolhelhelhelhelhelhelhelhelhelhe  \n",
       "4         Fin for for for for for for for for for for  \n",
       "5           Identdentdentdentdentdentdentdentdentdent  \n",
       "6          Explicplicplicplicplicplicplicplicplicplic  \n",
       "7                    Es 37 37 37 37 37 37 37 37 37 37  \n",
       "8                                         AAAAAAAAAAA  \n",
       "9                  Comolhelhelhelhelhelhelhelhelhelhe  \n",
       "10                     Qualirroirroirro 7 7 7 7 7 7 7  \n",
       "11  G Soviética Soviética Soviética Soviética Sovi...  \n",
       "12        Diserarerarerarerarerarerarerarerarerarerar  \n",
       "13      Classdentdentdentdentdentdentdentdentdentdent  \n",
       "14  Ex alimentar alimentar alimentar alimentar ali...  \n",
       "15                  Deslhelhelhelhelhelhelhelhelhelhe  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.head(16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt-moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
